{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA 1: Exploratory Analysis over 120 years of Olympic History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Details\n",
    "\n",
    "In this assignment, you will conduct a guided exploration over the Olympic History dataset. You will learn and use some of the most common exploration/aggregation/descriptive operations. This should also help you learn most of the key functionalities in Pandas.\n",
    "\n",
    "You will also learn how to use visualization libraries to identify patterns in data that will help in your further data analysis. You will also explore most popular chart types and how to use different libraries and styles to make your visualizations more attractive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Details\n",
    "\n",
    "In this assignment, we will work on 120 years of Olympic History dataset. Specifically, we will work on athlete_events.csv file from kaggle repository (https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results). The file athlete_events.csv contains 271.116 rows and 15 columns. This dataset begins with the 1896 Athens, Greece Olympics, and runs up to the 2016 Rio, Brazil Olympic Games. Each row corresponds to an athlete competing in an individual Olympic event. The columns of the data-set are:\n",
    "\n",
    "- ID - Unique number for each athlete\n",
    "- Name - Athlete's name\n",
    "- Sex - M or F\n",
    "- Age - Integer\n",
    "- Height - In centimeters\n",
    "- Weight - In kilograms\n",
    "- Team - Team name\n",
    "- NOC - National Olympic Committee 3-letter code\n",
    "- Games - Year and season\n",
    "- Year - Integer\n",
    "- Season - Summer or Winter\n",
    "- City - Host city\n",
    "- Sport - Sport\n",
    "- Event - Event\n",
    "- Medal - Gold, Silver, Bronze, or NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "#Array processing\n",
    "import numpy as np\n",
    "#Data analysis, wrangling and common exploratory operations\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "#For visualization. Matplotlib for basic viz and seaborn for more stylish figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Dataset\n",
    "The Python code below reads the Olympic History dataset into a Pandas data frame with the name df_Olympic. \n",
    "For this code to work, the file 'athlete_events.csv' must be in the same folder as this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'athlete_events.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9cab3563308f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#read the csv file into a Pandas data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_olympics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'athlete_events.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#return the first 5 rows of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_olympics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'athlete_events.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#read the csv file into a Pandas data frame\n",
    "df_olympics = pd.read_csv('athlete_events.csv', encoding='latin1')\n",
    "\n",
    "#return the first 5 rows of the dataset\n",
    "df_olympics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Statistical Exploratory Data Analysis\n",
    "Let us start with getting know the dataset. Your first task will be to get some basic information by using Pandas features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For each task below, look for a Pandas function to do the task.\n",
    "#Replace None in each task with your code.\n",
    "\n",
    "# 2.5 points\n",
    "#Task 1-a: Print the details of the df_olympics data frame (information such as number of rows,columns, name of columns, etc)\n",
    "print (\">>Task 1-a: Details of df_olympics data frame are: \\n\", df_olympics.describe() ) \n",
    "\n",
    "# 2.5 points\n",
    "#Task 1-b: Find the number of rows and columns in the df_olympics data frame.\n",
    "num_rows = df_olympics.shape[0]\n",
    "num_cols = df_olympics.shape[1]\n",
    "print (\"\\n\\n>>Task 1-b: Number of rows:%s and number of columns:%s\" % (num_rows, num_cols)) \n",
    "\n",
    "# 2.5 points\n",
    "#Task 1-c: Print the descriptive detail (min, max, quartiles etc) for 'Age' column of  the df_olympics\n",
    "print (\"\\n\\n>>Task 1-c: Descriptive details of year column are\\n\",df_olympics['Age'].describe())\n",
    "\n",
    "# 10 points\n",
    "#Task 1-d: Print the number of years from the first game until the last in our data-set, and the number of  unique values for 'games'.\n",
    "num_tot_years  = df_olympics['Year'].max() - df_olympics['Year'].min()\n",
    "num_uniq_games = len(df_olympics['Games'].unique().tolist())\n",
    "print (\"\\n\\n >>Task 1-d: In our dataset we have historical data for %s years, and for %s games. \" % (num_tot_years, num_uniq_games))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Aggregation & Filtering & Rank\n",
    "In this task, we will perform some very high level aggregation and filtering operations. \n",
    "Then, we will apply ranking on the results for some tasks. \n",
    "Pandas has a convenient and powerful syntax for aggregation, filtering, and ranking. \n",
    "DO NOT write a for loop. Pandas has built-in functions for all tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 points\n",
    "#Task 2-a: Find out the total number of female and male athletes that participated on the 2004 Olympics Games\n",
    "num_female_2004 = df_olympics.loc[(df_olympics['Year'] == 2004) & (df_olympics['Sex'] == 'F')].shape[0]\n",
    "num_male_2004   = df_olympics.loc[(df_olympics['Year'] == 2004) & (df_olympics['Sex'] == 'M')].shape[0]\n",
    "print (\">>Task 2-a: At the Olympics of 2004, there were participating %s female and %s male athletes\" \n",
    "       % (num_female_2004, num_male_2004))\n",
    "\n",
    "# 8 points\n",
    "#Task 2-b: Find out the total number of awarded metals for the year 1896, and the year 2016.\n",
    "#Utilize the property of cell's missing values\n",
    "num_medals_1896 = df_olympics['Medal'][df_olympics['Year'] == 1896].count()\n",
    "num_medals_2016 = df_olympics['Medal'][df_olympics['Year'] == 2016].count()\n",
    "\n",
    "print (\"\\n\\n>>Task 2-b: The total number of metals awarded in 1896 was %s, while in 2016 was %s\" \n",
    "       % (num_medals_1896, num_medals_2016))\n",
    "\n",
    "# 14 points\n",
    "#Task 2-c: Find out the top 10 athletes with the most gold medals for all years.\n",
    "top10_gold_athletes=df_olympics[df_olympics[\"Medal\"] == 'Gold']['Name'].value_counts().head(10)\n",
    "print (\"\\n\\n>>Task 2-c: The top 10 athletes for all years are: \\n%s\" % (top10_gold_athletes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Visualization\n",
    "In this task, you will perform a number of visualization tasks to get some intuition about the data. Visualization is a key component of exploration. You can choose to use either Matplotlib or Seaborn for plotting. The default figures generated from Matplotlib might look a bit ugly. So you might want to try Seaborn to get better figures. Seaborn has a variety of styles. Feel free to experiment with them and choose the one you like. We have earmarked 10 points for the aesthetics of your visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale = 1.3)\n",
    "\n",
    "# 15 points\n",
    "# Task 3-a: Draw a histogram for total number of athletes participated in all Summer Olympic Games. \n",
    "# Think of a way to nicely visualize the all years of Summer Olympics! \n",
    "#########################begin code for Task 3-a\n",
    "#df is a spare dataframe which stores data about athletes in \"Summer\" only\n",
    "df = df_olympics[df_olympics['Season'].str.match('Summer')]\n",
    "#dropping duplicates based on athlete name since we want the number of athletes\n",
    "# Same athlete could have taken part in multiple events\n",
    "df = df.drop_duplicates(['Year','Name'])\n",
    "# Histogram with bins = 120/4 which corresponds to interval between successive olympic games\n",
    "sns.distplot(df['Year'],hist=True, kde=False, \n",
    "             bins=int(124/4), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# seaborn kaavalante paidi esko...or matplotlib ante kindidi\n",
    "#df.hist(column='Year',bins=31)\n",
    "#########################end code for Task 3-a\n",
    "\n",
    "\n",
    "# 15 points\n",
    "# Task 3-b: Draw a \"vertical\" bar chart that lists the top-10 tallest althlets for all years.\n",
    "# Remember to make the bar chart into a vertical bar chart\n",
    "#########################begin code for Task 3-b \n",
    "\n",
    "#########################end code for Task 3-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_olympics[df_olympics['Year'] == 2012]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: \n",
    "Find out an 'interesting' information from your Olympic History dataset. Create a visualization for it and explain in a few lines your reasoning. \n",
    "\n",
    "This task is worth 20 points. Your result will be judged based on the uniqueness and quality of your work (having a meaningful result and an aesthetic visualization). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################begin code for Task 4\n",
    "\n",
    "number_of_countries = df.groupby('Year')['NOC'].nunique()\n",
    "plt.figure(figsize=(30,5))\n",
    "sns.barplot(number_of_countries.index, number_of_countries.values, alpha=0.8)\n",
    "plt.title(\"Year of Olympics vs No. of participating countries - bar\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(number_of_countries.index, number_of_countries.values, '.r-')\n",
    "plt.title(\"Year of olympics vs No. of participating countries - scatter-connected\")\n",
    "plt.xlim(1892,2020)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#We see from the bar graph and connected scatterplot that the number of countries \n",
    "#participating in 1980 olympics was drastically lower than other years. This is\n",
    "# because the 1980 olympics were held in Moscow and 66 Nations boycotted the games\n",
    "# due to Soviet invasion on Afghanistan\n",
    "\n",
    "\n",
    "# Code to print the number of cities and cities where olympics was held\n",
    "print(\"There are {} cities in whicn Olympics was conducted since 1896\".format(df_olympics[\"City\"].value_counts().nunique()))\n",
    "df_olympics.groupby([\"City\"])[\"Year\"].nunique().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# we see that only London and Athina have hosted the olympics thrice(maximum)\n",
    "#df['Team'][df['Year'] ==2008].value_counts()\n",
    "#########################end code for Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
